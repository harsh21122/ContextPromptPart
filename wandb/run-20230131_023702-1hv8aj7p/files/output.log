Length of Train dataset : 646 and Test dataset : 35
Length of Train loader : 65 and Test loader : 4
self.partnames :  ['head', 'neck', 'torso', 'legs', 'tail', 'background']
prompts :  [' the head of the cat.', ' the neck of the cat.', ' the torso of the cat.', ' the legs of the cat.', ' the tail of the cat.', ' the background of the cat.']
model device :  cuda
self.prompts : torch.Size([6, 77])
self.prompts : torch.Size([6, 1024])
self.prompts rquires grad :  <built-in method requires_grad_ of Tensor object at 0x7f105753a3b0>
Printing parameters and their gradient
gamma True
image_encoder.0.weight False
image_encoder.1.weight False
image_encoder.1.bias False
image_encoder.3.weight False
image_encoder.4.weight False
image_encoder.4.bias False
image_encoder.6.weight False
image_encoder.7.weight False
image_encoder.7.bias False
image_encoder.10.0.conv1.weight False
image_encoder.10.0.bn1.weight False
image_encoder.10.0.bn1.bias False
image_encoder.10.0.conv2.weight False
image_encoder.10.0.bn2.weight False
image_encoder.10.0.bn2.bias False
image_encoder.10.0.conv3.weight False
image_encoder.10.0.bn3.weight False
image_encoder.10.0.bn3.bias False
image_encoder.10.0.downsample.0.weight False
image_encoder.10.0.downsample.1.weight False
image_encoder.10.0.downsample.1.bias False
image_encoder.10.1.conv1.weight False
image_encoder.10.1.bn1.weight False
image_encoder.10.1.bn1.bias False
image_encoder.10.1.conv2.weight False
image_encoder.10.1.bn2.weight False
image_encoder.10.1.bn2.bias False
image_encoder.10.1.conv3.weight False
image_encoder.10.1.bn3.weight False
image_encoder.10.1.bn3.bias False
image_encoder.10.2.conv1.weight False
image_encoder.10.2.bn1.weight False
image_encoder.10.2.bn1.bias False
image_encoder.10.2.conv2.weight False
image_encoder.10.2.bn2.weight False
image_encoder.10.2.bn2.bias False
image_encoder.10.2.conv3.weight False
image_encoder.10.2.bn3.weight False
image_encoder.10.2.bn3.bias False
image_encoder.11.0.conv1.weight False
image_encoder.11.0.bn1.weight False
image_encoder.11.0.bn1.bias False
image_encoder.11.0.conv2.weight False
image_encoder.11.0.bn2.weight False
image_encoder.11.0.bn2.bias False
image_encoder.11.0.conv3.weight False
image_encoder.11.0.bn3.weight False
image_encoder.11.0.bn3.bias False
image_encoder.11.0.downsample.0.weight False
image_encoder.11.0.downsample.1.weight False
image_encoder.11.0.downsample.1.bias False
image_encoder.11.1.conv1.weight False
image_encoder.11.1.bn1.weight False
image_encoder.11.1.bn1.bias False
image_encoder.11.1.conv2.weight False
image_encoder.11.1.bn2.weight False
image_encoder.11.1.bn2.bias False
image_encoder.11.1.conv3.weight False
image_encoder.11.1.bn3.weight False
image_encoder.11.1.bn3.bias False
image_encoder.11.2.conv1.weight False
image_encoder.11.2.bn1.weight False
image_encoder.11.2.bn1.bias False
image_encoder.11.2.conv2.weight False
image_encoder.11.2.bn2.weight False
image_encoder.11.2.bn2.bias False
image_encoder.11.2.conv3.weight False
image_encoder.11.2.bn3.weight False
image_encoder.11.2.bn3.bias False
image_encoder.11.3.conv1.weight False
image_encoder.11.3.bn1.weight False
image_encoder.11.3.bn1.bias False
image_encoder.11.3.conv2.weight False
image_encoder.11.3.bn2.weight False
image_encoder.11.3.bn2.bias False
image_encoder.11.3.conv3.weight False
image_encoder.11.3.bn3.weight False
image_encoder.11.3.bn3.bias False
image_encoder.12.0.conv1.weight False
image_encoder.12.0.bn1.weight False
image_encoder.12.0.bn1.bias False
image_encoder.12.0.conv2.weight False
image_encoder.12.0.bn2.weight False
image_encoder.12.0.bn2.bias False
image_encoder.12.0.conv3.weight False
image_encoder.12.0.bn3.weight False
image_encoder.12.0.bn3.bias False
image_encoder.12.0.downsample.0.weight False
image_encoder.12.0.downsample.1.weight False
image_encoder.12.0.downsample.1.bias False
image_encoder.12.1.conv1.weight False
image_encoder.12.1.bn1.weight False
image_encoder.12.1.bn1.bias False
image_encoder.12.1.conv2.weight False
image_encoder.12.1.bn2.weight False
image_encoder.12.1.bn2.bias False
image_encoder.12.1.conv3.weight False
image_encoder.12.1.bn3.weight False
image_encoder.12.1.bn3.bias False
image_encoder.12.2.conv1.weight False
image_encoder.12.2.bn1.weight False
image_encoder.12.2.bn1.bias False
image_encoder.12.2.conv2.weight False
image_encoder.12.2.bn2.weight False
image_encoder.12.2.bn2.bias False
image_encoder.12.2.conv3.weight False
image_encoder.12.2.bn3.weight False
image_encoder.12.2.bn3.bias False
image_encoder.12.3.conv1.weight False
image_encoder.12.3.bn1.weight False
image_encoder.12.3.bn1.bias False
image_encoder.12.3.conv2.weight False
image_encoder.12.3.bn2.weight False
image_encoder.12.3.bn2.bias False
image_encoder.12.3.conv3.weight False
image_encoder.12.3.bn3.weight False
image_encoder.12.3.bn3.bias False
image_encoder.12.4.conv1.weight False
image_encoder.12.4.bn1.weight False
image_encoder.12.4.bn1.bias False
image_encoder.12.4.conv2.weight False
image_encoder.12.4.bn2.weight False
image_encoder.12.4.bn2.bias False
image_encoder.12.4.conv3.weight False
image_encoder.12.4.bn3.weight False
image_encoder.12.4.bn3.bias False
image_encoder.12.5.conv1.weight False
image_encoder.12.5.bn1.weight False
image_encoder.12.5.bn1.bias False
image_encoder.12.5.conv2.weight False
image_encoder.12.5.bn2.weight False
image_encoder.12.5.bn2.bias False
image_encoder.12.5.conv3.weight False
image_encoder.12.5.bn3.weight False
image_encoder.12.5.bn3.bias False
image_encoder.13.0.conv1.weight False
image_encoder.13.0.bn1.weight False
image_encoder.13.0.bn1.bias False
image_encoder.13.0.conv2.weight False
image_encoder.13.0.bn2.weight False
image_encoder.13.0.bn2.bias False
image_encoder.13.0.conv3.weight False
image_encoder.13.0.bn3.weight False
image_encoder.13.0.bn3.bias False
image_encoder.13.0.downsample.0.weight False
image_encoder.13.0.downsample.1.weight False
image_encoder.13.0.downsample.1.bias False
image_encoder.13.1.conv1.weight False
image_encoder.13.1.bn1.weight False
image_encoder.13.1.bn1.bias False
image_encoder.13.1.conv2.weight False
image_encoder.13.1.bn2.weight False
image_encoder.13.1.bn2.bias False
image_encoder.13.1.conv3.weight False
image_encoder.13.1.bn3.weight False
image_encoder.13.1.bn3.bias False
image_encoder.13.2.conv1.weight False
image_encoder.13.2.bn1.weight False
image_encoder.13.2.bn1.bias False
image_encoder.13.2.conv2.weight False
image_encoder.13.2.bn2.weight False
image_encoder.13.2.bn2.bias False
image_encoder.13.2.conv3.weight False
image_encoder.13.2.bn3.weight False
image_encoder.13.2.bn3.bias False
attnpool.positional_embedding True
attnpool.k_proj.weight True
attnpool.k_proj.bias True
attnpool.q_proj.weight True
attnpool.q_proj.bias True
attnpool.v_proj.weight True
attnpool.v_proj.bias True
attnpool.c_proj.weight True
attnpool.c_proj.bias True
align_context.memory_proj.0.weight True
align_context.memory_proj.0.bias True
align_context.memory_proj.1.weight True
align_context.memory_proj.1.bias True
align_context.memory_proj.2.weight True
align_context.memory_proj.2.bias True
align_context.text_proj.0.weight True
align_context.text_proj.0.bias True
align_context.text_proj.1.weight True
align_context.text_proj.1.bias True
align_context.decoder.0.self_attn.q_proj.weight True
align_context.decoder.0.self_attn.k_proj.weight True
align_context.decoder.0.self_attn.v_proj.weight True
align_context.decoder.0.self_attn.proj.weight True
align_context.decoder.0.self_attn.proj.bias True
align_context.decoder.0.cross_attn.q_proj.weight True
align_context.decoder.0.cross_attn.k_proj.weight True
align_context.decoder.0.cross_attn.v_proj.weight True
align_context.decoder.0.cross_attn.proj.weight True
align_context.decoder.0.cross_attn.proj.bias True
align_context.decoder.0.norm1.weight True
align_context.decoder.0.norm1.bias True
align_context.decoder.0.norm2.weight True
align_context.decoder.0.norm2.bias True
align_context.decoder.0.norm3.weight True
align_context.decoder.0.norm3.bias True
align_context.decoder.0.mlp.0.weight True
align_context.decoder.0.mlp.0.bias True
align_context.decoder.0.mlp.3.weight True
align_context.decoder.0.mlp.3.bias True
align_context.decoder.1.self_attn.q_proj.weight True
align_context.decoder.1.self_attn.k_proj.weight True
align_context.decoder.1.self_attn.v_proj.weight True
align_context.decoder.1.self_attn.proj.weight True
align_context.decoder.1.self_attn.proj.bias True
align_context.decoder.1.cross_attn.q_proj.weight True
align_context.decoder.1.cross_attn.k_proj.weight True
align_context.decoder.1.cross_attn.v_proj.weight True
align_context.decoder.1.cross_attn.proj.weight True
align_context.decoder.1.cross_attn.proj.bias True
align_context.decoder.1.norm1.weight True
align_context.decoder.1.norm1.bias True
align_context.decoder.1.norm2.weight True
align_context.decoder.1.norm2.bias True
align_context.decoder.1.norm3.weight True
align_context.decoder.1.norm3.bias True
align_context.decoder.1.mlp.0.weight True
align_context.decoder.1.mlp.0.bias True
align_context.decoder.1.mlp.3.weight True
align_context.decoder.1.mlp.3.bias True
align_context.decoder.2.self_attn.q_proj.weight True
align_context.decoder.2.self_attn.k_proj.weight True
align_context.decoder.2.self_attn.v_proj.weight True
align_context.decoder.2.self_attn.proj.weight True
align_context.decoder.2.self_attn.proj.bias True
align_context.decoder.2.cross_attn.q_proj.weight True
align_context.decoder.2.cross_attn.k_proj.weight True
align_context.decoder.2.cross_attn.v_proj.weight True
align_context.decoder.2.cross_attn.proj.weight True
align_context.decoder.2.cross_attn.proj.bias True
align_context.decoder.2.norm1.weight True
align_context.decoder.2.norm1.bias True
align_context.decoder.2.norm2.weight True
align_context.decoder.2.norm2.bias True
align_context.decoder.2.norm3.weight True
align_context.decoder.2.norm3.bias True
align_context.decoder.2.mlp.0.weight True
align_context.decoder.2.mlp.0.bias True
align_context.decoder.2.mlp.3.weight True
align_context.decoder.2.mlp.3.bias True
align_context.decoder.3.self_attn.q_proj.weight True
align_context.decoder.3.self_attn.k_proj.weight True
align_context.decoder.3.self_attn.v_proj.weight True
align_context.decoder.3.self_attn.proj.weight True
align_context.decoder.3.self_attn.proj.bias True
align_context.decoder.3.cross_attn.q_proj.weight True
align_context.decoder.3.cross_attn.k_proj.weight True
align_context.decoder.3.cross_attn.v_proj.weight True
align_context.decoder.3.cross_attn.proj.weight True
align_context.decoder.3.cross_attn.proj.bias True
align_context.decoder.3.norm1.weight True
align_context.decoder.3.norm1.bias True
align_context.decoder.3.norm2.weight True
align_context.decoder.3.norm2.bias True
align_context.decoder.3.norm3.weight True
align_context.decoder.3.norm3.bias True
align_context.decoder.3.mlp.0.weight True
align_context.decoder.3.mlp.0.bias True
align_context.decoder.3.mlp.3.weight True
align_context.decoder.3.mlp.3.bias True
align_context.decoder.4.self_attn.q_proj.weight True
align_context.decoder.4.self_attn.k_proj.weight True
align_context.decoder.4.self_attn.v_proj.weight True
align_context.decoder.4.self_attn.proj.weight True
align_context.decoder.4.self_attn.proj.bias True
align_context.decoder.4.cross_attn.q_proj.weight True
align_context.decoder.4.cross_attn.k_proj.weight True
align_context.decoder.4.cross_attn.v_proj.weight True
align_context.decoder.4.cross_attn.proj.weight True
align_context.decoder.4.cross_attn.proj.bias True
align_context.decoder.4.norm1.weight True
align_context.decoder.4.norm1.bias True
align_context.decoder.4.norm2.weight True
align_context.decoder.4.norm2.bias True
align_context.decoder.4.norm3.weight True
align_context.decoder.4.norm3.bias True
align_context.decoder.4.mlp.0.weight True
align_context.decoder.4.mlp.0.bias True
align_context.decoder.4.mlp.3.weight True
align_context.decoder.4.mlp.3.bias True
align_context.decoder.5.self_attn.q_proj.weight True
align_context.decoder.5.self_attn.k_proj.weight True
align_context.decoder.5.self_attn.v_proj.weight True
align_context.decoder.5.self_attn.proj.weight True
align_context.decoder.5.self_attn.proj.bias True
align_context.decoder.5.cross_attn.q_proj.weight True
align_context.decoder.5.cross_attn.k_proj.weight True
align_context.decoder.5.cross_attn.v_proj.weight True
align_context.decoder.5.cross_attn.proj.weight True
align_context.decoder.5.cross_attn.proj.bias True
align_context.decoder.5.norm1.weight True
align_context.decoder.5.norm1.bias True
align_context.decoder.5.norm2.weight True
align_context.decoder.5.norm2.bias True
align_context.decoder.5.norm3.weight True
align_context.decoder.5.norm3.bias True
align_context.decoder.5.mlp.0.weight True
align_context.decoder.5.mlp.0.bias True
align_context.decoder.5.mlp.3.weight True
align_context.decoder.5.mlp.3.bias True
align_context.out_proj.0.weight True
align_context.out_proj.0.bias True
align_context.out_proj.1.weight True
align_context.out_proj.1.bias True
decoder.conv_layers.0.weight True
decoder.conv_layers.0.bias True
decoder.conv_layers.2.weight True
decoder.conv_layers.2.bias True
decoder.conv_layers.3.weight True
decoder.conv_layers.3.bias True
decoder.conv_layers.5.weight True
decoder.conv_layers.5.bias True
EPOCH 1:
  batch 20 loss: 1.9826269686222076
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.9437389969825745
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.8574302673339844
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
LOSS train 1.947001090273261 valid 1.8399730026721954
Saved best model. Old loss 1000000.0 and new best loss 1.8399730026721954
EPOCH 2:
  batch 20 loss: 1.7984290659427642
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.7989116191864014
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.7203350603580474
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3, 4], device='cuda:0')
LOSS train 1.7894550450146198 valid 3.0402061343193054
EPOCH 3:
  batch 20 loss: 1.6633895277976989
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.5959528267383576
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.5699887990951538
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.6258241310715675 valid 3.0489348769187927
EPOCH 4:
  batch 20 loss: 1.5292038857936858
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.4964997470378876
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.5028428614139557
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.5272548124194145 valid 3.53172367811203
EPOCH 5:
  batch 20 loss: 1.4766198575496674
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.4441063582897187
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.4406609117984772
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.4699997007846832 valid 2.525184988975525
EPOCH 6:
  batch 20 loss: 1.4302475094795226
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.4171839714050294
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.4059582591056823
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.4344981033354998 valid 2.0545676350593567
EPOCH 7:
  batch 20 loss: 1.4053898930549622
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.3878497064113617
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.382375830411911
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.408901657909155 valid 1.8871042132377625
EPOCH 8:
  batch 20 loss: 1.3847666382789612
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.3638386070728301
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.3562695503234863
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.3831789065152407 valid 1.7705025672912598
Saved best model. Old loss 1.8399730026721954 and new best loss 1.7705025672912598
EPOCH 9:
  batch 20 loss: 1.351144516468048
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.3381203770637513
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.3338662147521974
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.356309937313199 valid 1.74277725815773
Saved best model. Old loss 1.7705025672912598 and new best loss 1.74277725815773
EPOCH 10:
  batch 20 loss: 1.3262645721435546
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.3194561660289765
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.3171500504016875
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.335678456351161 valid 1.6386679112911224
Saved best model. Old loss 1.74277725815773 and new best loss 1.6386679112911224
EPOCH 11:
  batch 20 loss: 1.3100180745124816
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2991892218589782
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.3114495038986207
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.3219912853091955 valid 1.6186569035053253
Saved best model. Old loss 1.6386679112911224 and new best loss 1.6186569035053253
EPOCH 12:
  batch 20 loss: 1.2964279413223267
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.288349449634552
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2922262489795684
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([3], device='cuda:0')
LOSS train 1.3073892500251532 valid 1.6479043662548065
EPOCH 13:
  batch 20 loss: 1.2838748574256897
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2759726762771606
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2710576713085175
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.2912840135395527 valid 1.664986491203308
EPOCH 14:
  batch 20 loss: 1.2667689085006715
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2564695537090302
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2556455314159394
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.273602170869708 valid 1.6790726482868195
EPOCH 15:
  batch 20 loss: 1.2533261895179748
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2471790432929992
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2478053092956543
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.2632319517433643 valid 1.6649060249328613
EPOCH 16:
  batch 20 loss: 1.250140166282654
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2398513793945312
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.228347474336624
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.2516947835683823 valid 1.7441839575767517
EPOCH 17:
  batch 20 loss: 1.230122411251068
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2183294892311096
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2150752425193787
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.233886819332838 valid 1.7518599331378937
EPOCH 18:
  batch 20 loss: 1.2125166356563568
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.2135117471218109
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.2035800218582153
pred unique :  tensor([0, 1, 2, 3, 4], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.2224714383482933 valid 1.6946306228637695
EPOCH 19:
  batch 20 loss: 1.215956211090088
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.1954912424087525
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.189352911710739
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.2127176187932491 valid 1.7146874964237213
EPOCH 20:
  batch 20 loss: 1.196894121170044
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.1854887306690216
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.175831824541092
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.1980473585426807 valid 1.7405644655227661
EPOCH 21:
  batch 20 loss: 1.178315770626068
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.1701704800128936
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.1622040808200835
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.1819156575948 valid 1.7245388329029083
EPOCH 22:
  batch 20 loss: 1.1748197674751282
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.1676460266113282
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.1539387464523316
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.1769639253616333 valid 1.693045288324356
EPOCH 23:
  batch 20 loss: 1.1665335059165955
pred unique :  tensor([0, 1, 3, 4], device='cuda:0')
  batch 40 loss: 1.1623290956020356
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.1483843922615051
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.1696353387087584 valid 1.711717426776886
EPOCH 24:
  batch 20 loss: 1.1519064366817475
pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.149513554573059
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.1392803192138672
pred unique :  tensor([0, 1, 3, 4], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.156979775056243 valid 1.7221431732177734
EPOCH 25:
  batch 20 loss: 1.142457765340805
pred unique :  tensor([0, 1, 3, 4], device='cuda:0')
  batch 40 loss: 1.1386006295681
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.135553526878357
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([0, 1, 3], device='cuda:0')
LOSS train 1.1491454262286425 valid 1.7618738114833832
EPOCH 26:
  batch 20 loss: 1.1248844981193542
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 40 loss: 1.1321276426315308
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  batch 60 loss: 1.122289788722992
pred unique :  tensor([0, 1, 3, 4, 5], device='cuda:0')
  val done :  0
pred unique :  tensor([1, 3], device='cuda:0')
LOSS train 1.1373594235628843 valid 1.787382423877716
EPOCH 27:
  batch 20 loss: 1.117867261171341
