Length of Train dataset : 646 and Test dataset : 35
Length of Train loader : 65 and Test loader : 4
self.partnames :  ['background', 'head', 'neck', 'torso', 'tail', 'legs']
prompts :  [' the background of the cat.', ' the head of the cat.', ' the neck of the cat.', ' the torso of the cat.', ' the tail of the cat.', ' the legs of the cat.']
model device :  cuda
self.prompts : torch.Size([6, 77])
self.prompts : torch.Size([6, 1024])
self.prompts rquires grad :  <built-in method requires_grad_ of Tensor object at 0x7fd6803e63b0>
layer: relu3_2,relu5_4
weighs: [0.33, 1.0]
/home/harsh21122/.conda/envs/part/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/harsh21122/.conda/envs/part/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Printing parameters and their gradient
gamma True
image_encoder.0.weight False
image_encoder.1.weight False
image_encoder.1.bias False
image_encoder.3.weight False
image_encoder.4.weight False
image_encoder.4.bias False
image_encoder.6.weight False
image_encoder.7.weight False
image_encoder.7.bias False
image_encoder.10.0.conv1.weight False
image_encoder.10.0.bn1.weight False
image_encoder.10.0.bn1.bias False
image_encoder.10.0.conv2.weight False
image_encoder.10.0.bn2.weight False
image_encoder.10.0.bn2.bias False
image_encoder.10.0.conv3.weight False
image_encoder.10.0.bn3.weight False
image_encoder.10.0.bn3.bias False
image_encoder.10.0.downsample.0.weight False
image_encoder.10.0.downsample.1.weight False
image_encoder.10.0.downsample.1.bias False
image_encoder.10.1.conv1.weight False
image_encoder.10.1.bn1.weight False
image_encoder.10.1.bn1.bias False
image_encoder.10.1.conv2.weight False
image_encoder.10.1.bn2.weight False
image_encoder.10.1.bn2.bias False
image_encoder.10.1.conv3.weight False
image_encoder.10.1.bn3.weight False
image_encoder.10.1.bn3.bias False
image_encoder.10.2.conv1.weight False
image_encoder.10.2.bn1.weight False
image_encoder.10.2.bn1.bias False
image_encoder.10.2.conv2.weight False
image_encoder.10.2.bn2.weight False
image_encoder.10.2.bn2.bias False
image_encoder.10.2.conv3.weight False
image_encoder.10.2.bn3.weight False
image_encoder.10.2.bn3.bias False
image_encoder.11.0.conv1.weight False
image_encoder.11.0.bn1.weight False
image_encoder.11.0.bn1.bias False
image_encoder.11.0.conv2.weight False
image_encoder.11.0.bn2.weight False
image_encoder.11.0.bn2.bias False
image_encoder.11.0.conv3.weight False
image_encoder.11.0.bn3.weight False
image_encoder.11.0.bn3.bias False
image_encoder.11.0.downsample.0.weight False
image_encoder.11.0.downsample.1.weight False
image_encoder.11.0.downsample.1.bias False
image_encoder.11.1.conv1.weight False
image_encoder.11.1.bn1.weight False
image_encoder.11.1.bn1.bias False
image_encoder.11.1.conv2.weight False
image_encoder.11.1.bn2.weight False
image_encoder.11.1.bn2.bias False
image_encoder.11.1.conv3.weight False
image_encoder.11.1.bn3.weight False
image_encoder.11.1.bn3.bias False
image_encoder.11.2.conv1.weight False
image_encoder.11.2.bn1.weight False
image_encoder.11.2.bn1.bias False
image_encoder.11.2.conv2.weight False
image_encoder.11.2.bn2.weight False
image_encoder.11.2.bn2.bias False
image_encoder.11.2.conv3.weight False
image_encoder.11.2.bn3.weight False
image_encoder.11.2.bn3.bias False
image_encoder.11.3.conv1.weight False
image_encoder.11.3.bn1.weight False
image_encoder.11.3.bn1.bias False
image_encoder.11.3.conv2.weight False
image_encoder.11.3.bn2.weight False
image_encoder.11.3.bn2.bias False
image_encoder.11.3.conv3.weight False
image_encoder.11.3.bn3.weight False
image_encoder.11.3.bn3.bias False
image_encoder.12.0.conv1.weight False
image_encoder.12.0.bn1.weight False
image_encoder.12.0.bn1.bias False
image_encoder.12.0.conv2.weight False
image_encoder.12.0.bn2.weight False
image_encoder.12.0.bn2.bias False
image_encoder.12.0.conv3.weight False
image_encoder.12.0.bn3.weight False
image_encoder.12.0.bn3.bias False
image_encoder.12.0.downsample.0.weight False
image_encoder.12.0.downsample.1.weight False
image_encoder.12.0.downsample.1.bias False
image_encoder.12.1.conv1.weight False
image_encoder.12.1.bn1.weight False
image_encoder.12.1.bn1.bias False
image_encoder.12.1.conv2.weight False
image_encoder.12.1.bn2.weight False
image_encoder.12.1.bn2.bias False
image_encoder.12.1.conv3.weight False
image_encoder.12.1.bn3.weight False
image_encoder.12.1.bn3.bias False
image_encoder.12.2.conv1.weight False
image_encoder.12.2.bn1.weight False
image_encoder.12.2.bn1.bias False
image_encoder.12.2.conv2.weight False
image_encoder.12.2.bn2.weight False
image_encoder.12.2.bn2.bias False
image_encoder.12.2.conv3.weight False
image_encoder.12.2.bn3.weight False
image_encoder.12.2.bn3.bias False
image_encoder.12.3.conv1.weight False
image_encoder.12.3.bn1.weight False
image_encoder.12.3.bn1.bias False
image_encoder.12.3.conv2.weight False
image_encoder.12.3.bn2.weight False
image_encoder.12.3.bn2.bias False
image_encoder.12.3.conv3.weight False
image_encoder.12.3.bn3.weight False
image_encoder.12.3.bn3.bias False
image_encoder.12.4.conv1.weight False
image_encoder.12.4.bn1.weight False
image_encoder.12.4.bn1.bias False
image_encoder.12.4.conv2.weight False
image_encoder.12.4.bn2.weight False
image_encoder.12.4.bn2.bias False
image_encoder.12.4.conv3.weight False
image_encoder.12.4.bn3.weight False
image_encoder.12.4.bn3.bias False
image_encoder.12.5.conv1.weight False
image_encoder.12.5.bn1.weight False
image_encoder.12.5.bn1.bias False
image_encoder.12.5.conv2.weight False
image_encoder.12.5.bn2.weight False
image_encoder.12.5.bn2.bias False
image_encoder.12.5.conv3.weight False
image_encoder.12.5.bn3.weight False
image_encoder.12.5.bn3.bias False
image_encoder.13.0.conv1.weight False
image_encoder.13.0.bn1.weight False
image_encoder.13.0.bn1.bias False
image_encoder.13.0.conv2.weight False
image_encoder.13.0.bn2.weight False
image_encoder.13.0.bn2.bias False
image_encoder.13.0.conv3.weight False
image_encoder.13.0.bn3.weight False
image_encoder.13.0.bn3.bias False
image_encoder.13.0.downsample.0.weight False
image_encoder.13.0.downsample.1.weight False
image_encoder.13.0.downsample.1.bias False
image_encoder.13.1.conv1.weight False
image_encoder.13.1.bn1.weight False
image_encoder.13.1.bn1.bias False
image_encoder.13.1.conv2.weight False
image_encoder.13.1.bn2.weight False
image_encoder.13.1.bn2.bias False
image_encoder.13.1.conv3.weight False
image_encoder.13.1.bn3.weight False
image_encoder.13.1.bn3.bias False
image_encoder.13.2.conv1.weight False
image_encoder.13.2.bn1.weight False
image_encoder.13.2.bn1.bias False
image_encoder.13.2.conv2.weight False
image_encoder.13.2.bn2.weight False
image_encoder.13.2.bn2.bias False
image_encoder.13.2.conv3.weight False
image_encoder.13.2.bn3.weight False
image_encoder.13.2.bn3.bias False
attnpool.positional_embedding True
attnpool.k_proj.weight True
attnpool.k_proj.bias True
attnpool.q_proj.weight True
attnpool.q_proj.bias True
attnpool.v_proj.weight True
attnpool.v_proj.bias True
attnpool.c_proj.weight True
attnpool.c_proj.bias True
align_context.memory_proj.0.weight True
align_context.memory_proj.0.bias True
align_context.memory_proj.1.weight True
align_context.memory_proj.1.bias True
align_context.memory_proj.2.weight True
align_context.memory_proj.2.bias True
align_context.text_proj.0.weight True
align_context.text_proj.0.bias True
align_context.text_proj.1.weight True
align_context.text_proj.1.bias True
align_context.decoder.0.self_attn.q_proj.weight True
align_context.decoder.0.self_attn.k_proj.weight True
align_context.decoder.0.self_attn.v_proj.weight True
align_context.decoder.0.self_attn.proj.weight True
align_context.decoder.0.self_attn.proj.bias True
align_context.decoder.0.cross_attn.q_proj.weight True
align_context.decoder.0.cross_attn.k_proj.weight True
align_context.decoder.0.cross_attn.v_proj.weight True
align_context.decoder.0.cross_attn.proj.weight True
align_context.decoder.0.cross_attn.proj.bias True
align_context.decoder.0.norm1.weight True
align_context.decoder.0.norm1.bias True
align_context.decoder.0.norm2.weight True
align_context.decoder.0.norm2.bias True
align_context.decoder.0.norm3.weight True
align_context.decoder.0.norm3.bias True
align_context.decoder.0.mlp.0.weight True
align_context.decoder.0.mlp.0.bias True
align_context.decoder.0.mlp.3.weight True
align_context.decoder.0.mlp.3.bias True
align_context.decoder.1.self_attn.q_proj.weight True
align_context.decoder.1.self_attn.k_proj.weight True
align_context.decoder.1.self_attn.v_proj.weight True
align_context.decoder.1.self_attn.proj.weight True
align_context.decoder.1.self_attn.proj.bias True
align_context.decoder.1.cross_attn.q_proj.weight True
align_context.decoder.1.cross_attn.k_proj.weight True
align_context.decoder.1.cross_attn.v_proj.weight True
align_context.decoder.1.cross_attn.proj.weight True
align_context.decoder.1.cross_attn.proj.bias True
align_context.decoder.1.norm1.weight True
align_context.decoder.1.norm1.bias True
align_context.decoder.1.norm2.weight True
align_context.decoder.1.norm2.bias True
align_context.decoder.1.norm3.weight True
align_context.decoder.1.norm3.bias True
align_context.decoder.1.mlp.0.weight True
align_context.decoder.1.mlp.0.bias True
align_context.decoder.1.mlp.3.weight True
align_context.decoder.1.mlp.3.bias True
align_context.decoder.2.self_attn.q_proj.weight True
align_context.decoder.2.self_attn.k_proj.weight True
align_context.decoder.2.self_attn.v_proj.weight True
align_context.decoder.2.self_attn.proj.weight True
align_context.decoder.2.self_attn.proj.bias True
align_context.decoder.2.cross_attn.q_proj.weight True
align_context.decoder.2.cross_attn.k_proj.weight True
align_context.decoder.2.cross_attn.v_proj.weight True
align_context.decoder.2.cross_attn.proj.weight True
align_context.decoder.2.cross_attn.proj.bias True
align_context.decoder.2.norm1.weight True
align_context.decoder.2.norm1.bias True
align_context.decoder.2.norm2.weight True
align_context.decoder.2.norm2.bias True
align_context.decoder.2.norm3.weight True
align_context.decoder.2.norm3.bias True
align_context.decoder.2.mlp.0.weight True
align_context.decoder.2.mlp.0.bias True
align_context.decoder.2.mlp.3.weight True
align_context.decoder.2.mlp.3.bias True
align_context.decoder.3.self_attn.q_proj.weight True
align_context.decoder.3.self_attn.k_proj.weight True
align_context.decoder.3.self_attn.v_proj.weight True
align_context.decoder.3.self_attn.proj.weight True
align_context.decoder.3.self_attn.proj.bias True
align_context.decoder.3.cross_attn.q_proj.weight True
align_context.decoder.3.cross_attn.k_proj.weight True
align_context.decoder.3.cross_attn.v_proj.weight True
align_context.decoder.3.cross_attn.proj.weight True
align_context.decoder.3.cross_attn.proj.bias True
align_context.decoder.3.norm1.weight True
align_context.decoder.3.norm1.bias True
align_context.decoder.3.norm2.weight True
align_context.decoder.3.norm2.bias True
align_context.decoder.3.norm3.weight True
align_context.decoder.3.norm3.bias True
align_context.decoder.3.mlp.0.weight True
align_context.decoder.3.mlp.0.bias True
align_context.decoder.3.mlp.3.weight True
align_context.decoder.3.mlp.3.bias True
align_context.decoder.4.self_attn.q_proj.weight True
align_context.decoder.4.self_attn.k_proj.weight True
align_context.decoder.4.self_attn.v_proj.weight True
align_context.decoder.4.self_attn.proj.weight True
align_context.decoder.4.self_attn.proj.bias True
align_context.decoder.4.cross_attn.q_proj.weight True
align_context.decoder.4.cross_attn.k_proj.weight True
align_context.decoder.4.cross_attn.v_proj.weight True
align_context.decoder.4.cross_attn.proj.weight True
align_context.decoder.4.cross_attn.proj.bias True
align_context.decoder.4.norm1.weight True
align_context.decoder.4.norm1.bias True
align_context.decoder.4.norm2.weight True
align_context.decoder.4.norm2.bias True
align_context.decoder.4.norm3.weight True
align_context.decoder.4.norm3.bias True
align_context.decoder.4.mlp.0.weight True
align_context.decoder.4.mlp.0.bias True
align_context.decoder.4.mlp.3.weight True
align_context.decoder.4.mlp.3.bias True
align_context.decoder.5.self_attn.q_proj.weight True
align_context.decoder.5.self_attn.k_proj.weight True
align_context.decoder.5.self_attn.v_proj.weight True
align_context.decoder.5.self_attn.proj.weight True
align_context.decoder.5.self_attn.proj.bias True
align_context.decoder.5.cross_attn.q_proj.weight True
align_context.decoder.5.cross_attn.k_proj.weight True
align_context.decoder.5.cross_attn.v_proj.weight True
align_context.decoder.5.cross_attn.proj.weight True
align_context.decoder.5.cross_attn.proj.bias True
align_context.decoder.5.norm1.weight True
align_context.decoder.5.norm1.bias True
align_context.decoder.5.norm2.weight True
align_context.decoder.5.norm2.bias True
align_context.decoder.5.norm3.weight True
align_context.decoder.5.norm3.bias True
align_context.decoder.5.mlp.0.weight True
align_context.decoder.5.mlp.0.bias True
align_context.decoder.5.mlp.3.weight True
align_context.decoder.5.mlp.3.bias True
align_context.out_proj.0.weight True
align_context.out_proj.0.bias True
align_context.out_proj.1.weight True
align_context.out_proj.1.bias True
decoder.conv_layers.0.weight True
decoder.conv_layers.0.bias True
decoder.conv_layers.2.weight True
decoder.conv_layers.2.bias True
decoder.conv_layers.3.weight True
decoder.conv_layers.3.bias True
decoder.conv_layers.5.weight True
decoder.conv_layers.5.bias True
EPOCH 1:
Loss :  2.205963611602783 4.596133708953857 6.802097320556641
Loss :  2.349900007247925 4.494576454162598 6.844476699829102
Loss :  2.360309600830078 4.640230178833008 7.000539779663086
Loss :  2.3102588653564453 4.6578240394592285 6.968082904815674
Loss :  1.9858155250549316 4.525928020477295 6.511743545532227
Loss :  2.4175660610198975 4.412102222442627 6.829668045043945
Loss :  2.203636407852173 4.502203941345215 6.705840110778809
Loss :  2.3818306922912598 4.3525776863098145 6.734408378601074
Loss :  2.435208559036255 4.648319721221924 7.083528518676758
Loss :  2.267169237136841 4.449639797210693 6.716809272766113
Loss :  2.3646275997161865 4.455857276916504 6.8204851150512695
Loss :  2.348062753677368 4.502864360809326 6.850927352905273
Loss :  2.3005130290985107 4.552789688110352 6.853302955627441
Loss :  2.318516731262207 4.558579921722412 6.877096652984619
Loss :  2.2939438819885254 4.266056537628174 6.560000419616699
Loss :  2.2421844005584717 4.5113911628723145 6.753575325012207
Loss :  2.159635066986084 4.635402202606201 6.795037269592285
Loss :  2.2912604808807373 4.688127517700195 6.979388236999512
Loss :  2.3434059619903564 4.491117477416992 6.8345232009887695
Loss :  2.2448160648345947 4.517162799835205 6.761979103088379
  batch 20 loss: 2.2448160648345947, 4.517162799835205, 6.761979103088379
  torch.unique(gt) :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
Loss :  2.4095685482025146 4.430167198181152 6.839735984802246
Loss :  2.3193366527557373 4.69187068939209 7.011207580566406
Loss :  2.451328754425049 4.547306537628174 6.998635292053223
Loss :  2.1760599613189697 4.593616962432861 6.76967716217041
Loss :  2.4227240085601807 4.624644756317139 7.047369003295898
Loss :  2.323401689529419 4.619964599609375 6.943366050720215
Loss :  2.0211117267608643 4.733316898345947 6.754428863525391
Loss :  2.1816186904907227 4.530633926391602 6.712252616882324
Loss :  2.202901840209961 4.452079772949219 6.65498161315918
Loss :  2.3424527645111084 4.501457691192627 6.843910217285156
Loss :  2.319680690765381 4.594974994659424 6.914655685424805
Loss :  2.1307406425476074 4.536709785461426 6.667450428009033
Loss :  2.1579909324645996 4.799417972564697 6.957408905029297
Loss :  2.1833271980285645 4.666487693786621 6.8498148918151855
Loss :  2.3315415382385254 5.080141544342041 7.411683082580566
Loss :  2.087678909301758 4.660619258880615 6.748298168182373
Loss :  2.2572734355926514 4.4670186042785645 6.724291801452637
Loss :  2.3728179931640625 4.613011360168457 6.9858293533325195
Loss :  2.305363416671753 4.597541809082031 6.902905464172363
Loss :  2.2007765769958496 4.683298110961914 6.884074687957764
  batch 40 loss: 2.2007765769958496, 4.683298110961914, 6.884074687957764
  torch.unique(gt) :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
Loss :  2.411789655685425 4.497229099273682 6.909018516540527
Loss :  2.266887664794922 4.77547025680542 7.042357921600342
Loss :  2.1998350620269775 4.444463729858398 6.644298553466797
Loss :  1.927978754043579 4.542628765106201 6.470607757568359
Loss :  2.1629037857055664 4.434309005737305 6.597212791442871
Loss :  2.2389209270477295 4.777364730834961 7.0162858963012695
Loss :  2.211503267288208 4.527386665344238 6.738889694213867
Loss :  2.238492488861084 4.465871334075928 6.704363822937012
Loss :  1.9563899040222168 4.702572822570801 6.658962726593018
Loss :  2.314913272857666 4.611893653869629 6.926806926727295
Loss :  2.249951124191284 4.485185146331787 6.735136032104492
Loss :  2.1728570461273193 4.381120681762695 6.553977966308594
Loss :  2.1946520805358887 4.396536827087402 6.591188907623291
Loss :  2.262052297592163 4.441888809204102 6.703941345214844
Loss :  2.1735918521881104 4.6602606773376465 6.833852767944336
Loss :  2.213656187057495 4.709521293640137 6.923177719116211
Loss :  2.168400287628174 4.505677223205566 6.67407751083374
Loss :  2.3011345863342285 4.835751056671143 7.136885643005371
Loss :  2.2816147804260254 4.499956130981445 6.781570911407471
Loss :  2.027317762374878 4.635148048400879 6.662466049194336
  batch 60 loss: 2.027317762374878, 4.635148048400879, 6.662466049194336
  torch.unique(gt) :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  pred unique :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
Loss :  2.0219955444335938 4.538035869598389 6.560031414031982
Loss :  2.186981439590454 4.776302814483643 6.963284492492676
Loss :  2.2479984760284424 4.3414225578308105 6.589421272277832
Loss :  2.0706112384796143 4.423283576965332 6.493894577026367
Loss :  2.3556082248687744 4.028391361236572 6.383999824523926
Loss :  2.112210512161255 4.433405876159668 6.545616149902344
  val done :  0
torch.unique(gt) :  tensor([0, 1, 2, 3, 4, 5], device='cuda:0')
  pred unique :  tensor([0, 2, 3, 4, 5], device='cuda:0')
Loss :  2.10385799407959 4.403797626495361 6.507655620574951
Loss :  2.032029628753662 4.488926410675049 6.520956039428711
Traceback (most recent call last):
  File "/ssd-scratch/harsh21122/ContextPromptPart/train.py", line 332, in <module>
    main(args)
  File "/ssd-scratch/harsh21122/ContextPromptPart/train.py", line 273, in main
    avg_vloss, avg_vloss_ce, avg_vloss_cont  = validation(encoder, zoo_feat_net, testLoader, loss_fn, args)
ValueError: not enough values to unpack (expected 3, got 2)